{
  "hash": "9b3c661e78bae813398428d63c57b342",
  "result": {
    "markdown": "---\ntitle: \"Basics of Pytorch\"\nauthor: \"Rhys McAlister\"\ndate: \"2022-10-16\"\ncategories: [news,analysis]\nimage: \"image.jpg\"\neditor: \n  markdown: \n    wrap: sentence\n---\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\n# Imports\nimport time\nimport random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# PyTorch libraries\nimport torch\nfrom torch import nn\nfrom torchvision import datasets\nfrom torch.utils.data import DataLoader\nfrom torchvision.transforms import ToTensor\n```\n:::\n\n\nPytorch can be used for the direct construction of tensors in the following manner.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\n# From a list\na = torch.tensor([0,1,2])\n\n# From a tuple of tuples\nb = ((1.0,1.1), (1.2,1.3))\nb = torch.tensor(b)\n\n# From a numpy array\nc = np.ones([2,3])\nc = torch.tensor(c)\n\nprint(f\"Tensor a: {a}\")\nprint(f\"Tensor b: {b}\")\nprint(f\"Tensor c: {c}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTensor a: tensor([0, 1, 2])\nTensor b: tensor([[1.0000, 1.1000],\n        [1.2000, 1.3000]])\nTensor c: tensor([[1., 1., 1.],\n        [1., 1., 1.]], dtype=torch.float64)\n```\n:::\n:::\n\n\nIt is also possible to create tensors from various forms of random number distributions.\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\n# Uniform distribution\na = torch.rand(1, 3)\n\n# Normal distribution\nb = torch.randn(3, 4)\n\n# There are also constructors that allow us to construct\n# a tensor according to the above constructors, but with\n# dimensions equal to another tensor.\n\nc = torch.zeros_like(a)\nd = torch.rand_like(c)\n\nprint(f\"Tensor a: {a}\")\nprint(f\"Tensor b: {b}\")\nprint(f\"Tensor c: {c}\")\nprint(f\"Tensor d: {d}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTensor a: tensor([[0.5915, 0.8699, 0.6506]])\nTensor b: tensor([[ 0.8530, -0.2655,  1.2587, -0.3826],\n        [ 1.6196, -0.5862, -0.1411,  1.6425],\n        [ 0.2468,  0.1446, -1.1215, -2.3926]])\nTensor c: tensor([[0., 0., 0.]])\nTensor d: tensor([[0.7368, 0.2951, 0.8130]])\n```\n:::\n:::\n\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nimport torch\ntorch.manual_seed(0)\n\nimport random\nrandom.seed(0)\n\nimport numpy as np\nnp.random.seed(0)\n\nseed = 10\n```\n:::\n\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\ndef set_seed(seed=None, seed_torch=True):\n  \"\"\"\n  Function that controls randomness. NumPy and random modules must be imported.\n\n  Args:\n    seed : Integer\n      A non-negative integer that defines the random state. Default is `None`.\n    seed_torch : Boolean\n      If `True` sets the random seed for pytorch tensors, so pytorch module\n      must be imported. Default is `True`.\n\n  Returns:\n    Nothing.\n  \"\"\"\n  if seed is None:\n    seed = np.random.choice(2 ** 32)\n  random.seed(seed)\n  np.random.seed(seed)\n  if seed_torch:\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True\n\n  print(f'Random seed {seed} has been set.')\n```\n:::\n\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\ndef simplefun(seed=True, my_seed=None):\n  \"\"\"\n  Helper function to verify effectiveness of set_seed attribute\n\n  Args:\n    seed: Boolean\n      Specifies if seed value is provided or not\n    my_seed: Integer\n      Initializes seed to specified value\n\n  Returns:\n    Nothing\n  \"\"\"\n  if seed:\n    set_seed(seed=my_seed)\n\n  # uniform distribution\n  a = torch.rand(1, 3)\n  # normal distribution\n  b = torch.randn(3, 4)\n\n  print(\"Tensor a: \", a)\n  print(\"Tensor b: \", b)\n```\n:::\n\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nsimplefun(seed=True, my_seed=0)  # Turn `seed` to `False` or change `my_seed`\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRandom seed 0 has been set.\nTensor a:  tensor([[0.4963, 0.7682, 0.0885]])\nTensor b:  tensor([[ 0.3643,  0.1344,  0.1642,  0.3058],\n        [ 0.2100,  0.9056,  0.6035,  0.8110],\n        [-0.0451,  0.8797,  1.0482, -0.0445]])\n```\n:::\n:::\n\n\nPytorch also provides equivalents of numpy .`linscape()` and `.arrange()` functions which operate as you would expect.\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\na = torch.arange(0, 10, step=1)\nb = np.arange(0, 10, step=1)\n\nc = torch.linspace(0, 5, steps=11)\nd = np.linspace(0, 5, num=11)\n\nprint(f\"Tensor a: {a}\\n\")\nprint(f\"Numpy array b: {b}\\n\")\nprint(f\"Tensor c: {c}\\n\")\nprint(f\"Numpy array d: {d}\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTensor a: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n\nNumpy array b: [0 1 2 3 4 5 6 7 8 9]\n\nTensor c: tensor([0.0000, 0.5000, 1.0000, 1.5000, 2.0000, 2.5000, 3.0000, 3.5000, 4.0000,\n        4.5000, 5.0000])\n\nNumpy array d: [0.  0.5 1.  1.5 2.  2.5 3.  3.5 4.  4.5 5. ]\n\n```\n:::\n:::\n\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\ndef tensor_creation(Z):\n  \"\"\"\n  A function that creates various tensors.\n\n  Args:\n    Z: numpy.ndarray\n      An array of shape (3,4)\n\n  Returns:\n    A : Tensor\n      20 by 21 tensor consisting of ones\n    B : Tensor\n      A tensor with elements equal to the elements of numpy array Z\n    C : Tensor\n      A tensor with the same number of elements as A but with values âˆ¼U(0,1)\n    D : Tensor\n      A 1D tensor containing the even numbers between 4 and 40 inclusive.\n  \"\"\"\n  #################################################\n  ## TODO for students: fill in the missing code\n  ## from the first expression\n  \n  #################################################\n  A = torch.ones(20,21)\n  B = torch.tensor(Z)\n  C = torch.randn(20,21)\n  D = torch.linspace(4,41, steps=2)\n  \n  return A, B, C, D\n\n\n# numpy array to copy later\nZ = np.vander([1, 2, 3], 4)\n\n# Uncomment below to check your function!\nA, B, C, D = tensor_creation(Z)\n```\n:::\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}